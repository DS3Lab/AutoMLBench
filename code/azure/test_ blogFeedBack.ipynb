{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "\n",
        "def init(model_path=\"model.pkl\"):\n",
        "    global model\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "def predict(data):\n",
        "    try:\n",
        "        #data = np.array(json.loads(data))\n",
        "        result = model.predict(data)\n",
        "        # You can return any data type, as long as it is JSON serializable.\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return error\n",
        "\n",
        "\n",
        "def predict_proba(data):\n",
        "    try:\n",
        "        #data = np.array(json.loads(data))\n",
        "        result = model.predict_proba(data)\n",
        "        # You can return any data type, as long as it is JSON serializable.\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        error = str(e)\n",
        "        return error\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618817830904
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_name = ''\n",
        "target = 'y'\n",
        "model_path = \"blogFeedBack_model.pkl\"\n",
        "test_file = \"blogFeedBack_test.csv\"\n",
        "\n",
        "init(model_path)\n",
        "\n",
        "test_df = pd.read_csv(test_file)\n",
        "y_true = test_df[target]\n",
        "\n",
        "y_pred = predict(test_df.drop([target], axis=1))\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "print(\"test mse = {}\".format(mse))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test mse = 1.0702536595989807e-05\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618817347252
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## predcict test dataset on Kaggle\n",
        "\n",
        "kaggle_submit_head = [\"Id\", \"Action\"]\n",
        "\n",
        "kaggle_test_file = \"kaggle-test-d_aea.csv\"\n",
        "kaggle_pred_file = \"kaggle-test-d_aea-predictions.csv\"\n",
        "\n",
        "kaggle_test_df = pd.read_csv(kaggle_test_file)\n",
        "kaggle_test_id = np.array(kaggle_test_df[id_name])\n",
        "#kaggle_y_true = np.array(kaggle_test_df[target])\n",
        "\n",
        "print(kaggle_test_df.head())\n",
        "print(kaggle_test_df.shape)\n",
        "\n",
        "kaggle_y_pred = predict(kaggle_test_df.drop([id_name], axis=1))\n",
        "\n",
        "print(kaggle_y_pred.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
            "0   1     78766   72734         118079         118080         117878   \n",
            "1   2     40644    4378         117961         118327         118507   \n",
            "2   3     75443    2395         117961         118300         119488   \n",
            "3   4     43219   19986         117961         118225         118403   \n",
            "4   5     42093   50015         117961         118343         119598   \n",
            "\n",
            "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
            "0      117879            118177        19721     117880  \n",
            "1      118863            122008       118398     118865  \n",
            "2      118172            301534       249618     118175  \n",
            "3      120773            136187       118960     120774  \n",
            "4      118422            300136       118424     118425  \n",
            "(58921, 10)\n",
            "(58921,)\n"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616676962376
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(kaggle_test_id.shape)\n",
        "\n",
        "assert kaggle_y_pred.shape == kaggle_test_id.shape\n",
        "\n",
        "kaggle_pred_df = pd.DataFrame({kaggle_submit_head[0]: kaggle_test_id, kaggle_submit_head[1]: kaggle_y_pred})\n",
        "\n",
        "print(kaggle_pred_df.head())\n",
        "\n",
        "\n",
        "kaggle_pred_df.to_csv(kaggle_pred_file, index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(58921,)\n",
            "   Id  Action\n",
            "0   1       1\n",
            "1   2       1\n",
            "2   3       1\n",
            "3   4       1\n",
            "4   5       1\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1616676939313
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}